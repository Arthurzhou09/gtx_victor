{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1746479078034,
     "user": {
      "displayName": "Victor Huang",
      "userId": "04633402498328162113"
     },
     "user_tz": 240
    },
    "id": "ln2B3G66zMKo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746479078848,
     "user": {
      "displayName": "Victor Huang",
      "userId": "04633402498328162113"
     },
     "user_tz": 240
    },
    "id": "-zil3EDU2tij"
   },
   "outputs": [],
   "source": [
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, in_g, in_s, inter_channels):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.Wg = nn.Conv2d(in_g, inter_channels, kernel_size=1, stride=2)\n",
    "        self.Ws = nn.Conv2d(in_s, inter_channels, kernel_size=1)\n",
    "        self.psi = nn.Conv2d(inter_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, g, s):\n",
    "        Wg = self.Wg(g)\n",
    "        Ws = self.Ws(s)\n",
    "        out = F.relu(Wg + Ws)\n",
    "        out = self.psi(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        out = F.interpolate(out, size=g.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return out * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746479080877,
     "user": {
      "displayName": "Victor Huang",
      "userId": "04633402498328162113"
     },
     "user_tz": 240
    },
    "id": "2m7rW1mnCbyB"
   },
   "outputs": [],
   "source": [
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.params = params\n",
    "\n",
    "        nf2d = params['nFilters2D'] // 2\n",
    "        nf3d = params['nFilters3D'] // 2\n",
    "\n",
    "        # Optical branch (2D)\n",
    "        self.op_branch = nn.Sequential(\n",
    "            nn.Conv2d(2, nf2d, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Conv2d(nf2d, nf2d, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Conv2d(nf2d, nf2d, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )\n",
    "\n",
    "        # Fluorescence branch (3D)\n",
    "        self.fl_conv3d = nn.Sequential(\n",
    "            nn.Conv3d(1, nf3d, kernel_size=params['kernelConv3D'], stride=params['strideConv3D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Conv3d(nf3d, nf3d, kernel_size=params['kernelConv3D'], stride=params['strideConv3D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75),\n",
    "            nn.Conv3d(nf3d, nf3d, kernel_size=params['kernelConv3D'], stride=params['strideConv3D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Post-concat\n",
    "        self.conv_post_1 = nn.Sequential(\n",
    "            nn.Conv2d(nf2d + nf3d * params['nF'], 256, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_post_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_post_3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=params['kernelConv2D'], stride=params['strideConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Attention Gates\n",
    "        self.att1 = AttentionGate(1024, 512, 512)\n",
    "        self.att2 = AttentionGate(512, 256, 256)\n",
    "        self.att3 = AttentionGate(256, nf2d + nf3d * params['nF'], 128)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(1024, 512, kernel_size=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_dec1 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(512, 256, kernel_size=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_dec2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(256, 128, kernel_size=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_dec3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Output layers for QF and DF\n",
    "        self.out_qf = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=params['kernelConv2D'], padding='same')\n",
    "        )\n",
    "\n",
    "        self.out_df = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=params['kernelConv2D'], padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=params['kernelConv2D'], padding='same')\n",
    "        )\n",
    "\n",
    "    def forward(self, inOP, inFL):\n",
    "        op = self.op_branch(inOP)\n",
    "        fl = self.fl_conv3d(inFL)\n",
    "        fl = fl.view(fl.size(0), -1, fl.size(3), fl.size(4))  # Flatten channels\n",
    "        x0 = torch.cat([op, fl], dim=1)\n",
    "\n",
    "        x1 = self.conv_post_1(x0)\n",
    "        x2 = self.conv_post_2(self.pool(x1))\n",
    "        x3 = self.conv_post_3(self.pool(x2))\n",
    "\n",
    "        att1 = self.att1(x3, x2)\n",
    "        x = self.up1(x3)\n",
    "        x = torch.cat([x, att1], dim=1)\n",
    "        x = self.conv_dec1(x)\n",
    "\n",
    "        att2 = self.att2(x, x1)\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, att2], dim=1)\n",
    "        x = self.conv_dec2(x)\n",
    "\n",
    "        att3 = self.att3(x, x0)\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x, att3], dim=1)\n",
    "        x = self.conv_dec3(x)\n",
    "\n",
    "        qf = self.out_qf(x)\n",
    "        df = self.out_df(x)\n",
    "        return qf, df\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGXLac98npnq+elN8fH5VJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gtx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
